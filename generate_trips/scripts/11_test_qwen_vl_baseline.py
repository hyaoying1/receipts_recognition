import os
import base64
import json
import time
from datetime import datetime
from pathlib import Path
import re
from openai import OpenAI

# ================== åŸºæœ¬é…ç½® ==================
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
API_KEY_ENV = "DASHSCOPE_API_KEY"

# å›¾ç‰‡æ‰€åœ¨ç›®å½•ï¼ˆé»˜è®¤ ./picturesï¼Œä¸‹å±‚æ‰€æœ‰ jpg/png ç›´æ¥å½“ä½œè¡Œç¨‹å•æ¥æµ‹ï¼‰
ROOT_DIR = "./pictures/è¡Œç¨‹å•"

# ç»“æœè¾“å‡ºè·¯å¾„
OUTPUT_PATH = Path("outputs/qwen_vl_trip_results.json")

# éœ€è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ï¼ˆä½ ä¹Ÿå¯ä»¥åˆ æ‰/å¢å‡ï¼‰
MODELS = [
    "qwen-vl-plus",
    "qwen-vl-max",
    "qwen2.5-vl-3b-instruct",
    "qwen2.5-vl-7b-instruct",
    "qwen2.5-vl-32b-instruct",
    "qwen2.5-vl-72b-instruct",
    "qwen3-vl-8b-instruct",
    "qwen3-vl-30b-a3b-instruct",
]

# ================== Promptï¼šè¿™é‡Œåªæµ‹è¡Œç¨‹å• ==================
# ğŸ‘‰ è¿™é‡Œä½ å¯ä»¥ç›´æ¥æ¢æˆåˆšåˆšé‚£æ®µé•¿çš„ SYSTEM_PROMPT / TRIP_QUERY
TRIP_QUERY = """ä½ æ˜¯ä¸€åç¥¨æ®è§£æåŠ©æ‰‹ã€‚è¯·ä»ç»™å®šçš„è¡Œç¨‹å•/æ‰“è½¦ç¥¨å›¾ç‰‡ä¸­è¯»å–ä¿¡æ¯ï¼Œåªè¾“å‡ºä¸€ä¸ªåˆæ³•çš„ JSONã€‚

è¾“å‡ºçš„ JSON ç»“æ„å’Œå­—æ®µå«ä¹‰å¦‚ä¸‹ï¼ˆé”®åå’ŒåµŒå¥—ç»“æ„å¿…é¡»ä¿æŒå®Œå…¨ä¸€è‡´ï¼‰ï¼š

{
  "type": "è¡Œç¨‹å•",
  "vendor": å¼€ç¥¨æ–¹/å¹³å°/ä¾›åº”å•†åç§°ï¼Œå­—ç¬¦ä¸²ï¼›æ— æ³•ç¡®å®šæ—¶ä¸º null,
  "apply_date": ç”³è¯·æ—¥æœŸï¼Œæ ¼å¼ä¸º "YYYY-MM-DD"ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null,
  "start_date": è¡Œç¨‹å¼€å§‹æ—¥æœŸï¼ˆæ•´ä¸ªè¡Œç¨‹å•çš„èµ·å§‹æ—¥æœŸï¼‰ï¼Œæ ¼å¼ä¸º "YYYY-MM-DD"ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null,
  "end_date": è¡Œç¨‹ç»“æŸæ—¥æœŸï¼ˆæ•´ä¸ªè¡Œç¨‹å•çš„ç»“æŸæ—¥æœŸï¼‰ï¼Œæ ¼å¼ä¸º "YYYY-MM-DD"ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null,
  "trips": [
    {
      "city": æœ¬æ¡è¡Œç¨‹æ‰€åœ¨åŸå¸‚åç§°ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡å‡å¯ï¼‰ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null,
      "date": æœ¬æ¡è¡Œç¨‹æ—¥æœŸï¼Œæ ¼å¼ä¸º "YYYY-MM-DD"ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null,
      "start_time": æœ¬æ¡è¡Œç¨‹çš„å‡ºå‘æ—¶é—´ï¼Œæ ¼å¼ä¸º "YYYY-MM-DD HH:MM:SS"ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null,
      "line_amount": æ­¤æ®µé‡‘é¢æ•°å­—ï¼ˆä¾‹å¦‚ 23.50ï¼Œç²¾ç¡®åˆ°å°æ•°ç‚¹åä¸¤ä½ï¼‰ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null,
      "currency": å¸ç§ï¼ˆå¦‚ "CNY"ï¼‰ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null
    }
  ],
  "total_amount": è¡Œç¨‹å•æ€»é‡‘é¢æ•°å­—ï¼ˆä¾‹å¦‚ 256.80ï¼Œç²¾ç¡®åˆ°å°æ•°ç‚¹åä¸¤ä½ï¼‰ï¼Œæ— æ³•ç¡®å®šæ—¶ä¸º null
}


è¡¥å……è§„åˆ™ï¼ˆå¾ˆé‡è¦ï¼‰ï¼š

1. å…³äº "start_date" å’Œ "end_date"
   - å¤§éƒ¨åˆ†è¡Œç¨‹å•åœ¨è¡¨å¤´ä¼šæ˜ç¡®ç»™å‡ºæ•´ä¸ªè¡Œç¨‹çš„èµ·æ­¢æ—¥æœŸï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªæ—¥æœŸåŒºé—´ï¼‰ï¼Œä¾‹å¦‚ï¼š
     - "è¡Œç¨‹æ—¥æœŸï¼š2024-12-30 è‡³ 2025-01-02"
   - å¦‚æœè¡¨å¤´**åŒæ—¶ç»™å‡ºäº†èµ·å§‹æ—¥æœŸå’Œç»“æŸæ—¥æœŸ**ï¼š
     - ç›´æ¥ä½¿ç”¨è¡¨å¤´ä¸­æœ€æ—©çš„æ—¥æœŸä½œä¸º "start_date"ï¼›
     - ä½¿ç”¨è¡¨å¤´ä¸­æœ€æ™šçš„æ—¥æœŸä½œä¸º "end_date"ã€‚
   - å¦‚æœè¡¨å¤´åªç»™å‡º**å•ä¸€æ—¥æœŸ**æˆ–æ¨¡ç³Šä¿¡æ¯ï¼ˆä¾‹å¦‚â€œè¡Œç¨‹æ—¥æœŸï¼š2024-03-15â€ï¼‰ï¼š
     - å°†æ‰€æœ‰æ˜ç»†æ—¥æœŸä¸­æœ€æ—©çš„é‚£ä¸€å¤©å¡«å…¥ "start_date"ï¼›
     - å°†æ‰€æœ‰æ˜ç»†æ—¥æœŸä¸­æœ€æ™šçš„é‚£ä¸€å¤©å¡«å…¥ "end_date"ã€‚
   - å¦‚æœè¡¨å¤´å®Œå…¨ä¸æä¾›èµ·æ­¢æ—¥æœŸä¿¡æ¯ï¼ˆæ²¡æœ‰ä»»ä½•æ—¥æœŸåŒºé—´ï¼‰ï¼š
     - å°†æ‰€æœ‰æ˜ç»†æ—¥æœŸä¸­æœ€æ—©çš„é‚£ä¸€å¤©å¡«å…¥ "start_date"ï¼›
     - å°†æ‰€æœ‰æ˜ç»†æ—¥æœŸä¸­æœ€æ™šçš„é‚£ä¸€å¤©å¡«å…¥ "end_date"ã€‚
   - å¦‚æœæ—¢æ— æ³•ä»è¡¨å¤´ä¹Ÿæ— æ³•ä»æ˜ç»†ä¸­æ¨æ–­ä»»ä½•æ—¥æœŸï¼Œåˆ™ "start_date" å’Œ "end_date" éƒ½å¡« nullã€‚

2. å…³äº "date" å’Œ "start_time" çš„è¡¥å…¨ä¸æ¨æ–­
   - ç›®æ ‡æ ¼å¼ï¼š
     - "date": "YYYY-MM-DD"
     - "start_time": "YYYY-MM-DD HH:MM:SS"
   - å¦‚æœæ˜ç»†ä¸­åªç»™å‡ºäº†â€œæœˆ-æ—¥ æ—¶:åˆ†â€ï¼ˆå¦‚ "12-31 23:50"ï¼‰ï¼Œæ²¡æœ‰å¹´ä»½ã€æ²¡æœ‰ç§’ï¼š
     - ä¼˜å…ˆä»è¡¨å¤´çš„è¡Œç¨‹èµ·æ­¢æ—¶é—´è·å–å¹´ä»½ä¿¡æ¯ï¼›
     - è‹¥è¡¨å¤´æ˜¾ç¤ºäº†è¡Œç¨‹èµ·æ­¢æ—¥æœŸåŒºé—´ï¼ˆä¾‹å¦‚ "2024-12-30 è‡³ 2025-01-02"ï¼‰ï¼š
       - å¯¹äºæ¯ä¸€æ¡åªåŒ…å«â€œæœˆ-æ—¥â€çš„è®°å½•ï¼Œåº”é€‰æ‹©ä¸€ä¸ªå¹´ä»½ï¼Œä½¿å¾—ç»„åˆåçš„å®Œæ•´æ—¥æœŸ (YYYY-MM-DD) å°½é‡è½åœ¨è¡Œç¨‹èµ·æ­¢æ—¥æœŸåŒºé—´å†…ï¼›
       - å¦‚æœåŒºé—´è·¨å¹´ï¼Œæ ¹æ®æ—¥æœŸåŒºé—´è‡ªè¡Œåˆ¤æ–­æœ€åˆç†çš„å¹´ä»½å½’å±ï¼Œä½¿æ‰€æœ‰è¡Œç¨‹æ—¥æœŸæ•´ä½“å°½é‡è½åœ¨è¡¨å¤´ç»™å‡ºçš„èµ·æ­¢æ—¥æœŸèŒƒå›´å†…ã€‚
     - è‹¥ç§’æ•°ç¼ºå¤±ï¼Œåˆ™è¡¥ä¸º ":00"ã€‚
     - ä¾‹å¦‚ï¼šæ˜ç»†å†™çš„æ˜¯ "12-31 23:50"ï¼Œè¡¨å¤´åŒºé—´æ˜¯ "2024-12-30 è‡³ 2025-01-02"ï¼Œåˆ™ï¼š
       - "date": "2024-12-31"
       - "start_time": "2024-12-31 23:50:00"
   - å¦‚æœæ—¢æ‰¾ä¸åˆ°å¹´ä»½ä¿¡æ¯ï¼Œåˆæ— æ³•åˆ¤æ–­å¹´ä»½ï¼ˆä¾‹å¦‚ç¥¨æ®ä¸Šå®Œå…¨æ²¡æœ‰ä»»ä½•å¹´ä»½ï¼‰ï¼Œåˆ™ï¼š
     - "date" å’Œ "start_time" éƒ½å¡« nullã€‚


è¾“å‡ºè¦æ±‚ï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
1ï¼‰åªè¾“å‡ºä¸€ä¸ªç¬¦åˆä¸Šè¿°ç»“æ„çš„ JSON å¯¹è±¡ï¼›
2ï¼‰é”®åå¿…é¡»å…¨éƒ¨ä½¿ç”¨ä¸Šè¿°è‹±æ–‡åç§°ï¼Œä¸èƒ½å¢åˆ æˆ–æ”¹åï¼›
3ï¼‰æ‰€æœ‰å­—ç¬¦ä¸²å€¼å¿…é¡»ç”¨è‹±æ–‡åŒå¼•å·åŒ…è£¹ï¼›
4ï¼‰ä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„è§£é‡Šæ€§æ–‡å­—ã€æ³¨é‡Šæˆ–å¤šä½™å†…å®¹ï¼Œåªè¾“å‡º JSONã€‚
"""


# ================== å·¥å…·å‡½æ•° ==================
def iter_images(root_dir: str):
    """éå†ç›®å½•ä¸‹æ‰€æœ‰ jpg / jpeg / png å›¾ç‰‡"""
    root = Path(root_dir)
    for img_path in sorted(root.iterdir()):
        if img_path.is_file() and img_path.suffix.lower() in (".jpg", ".jpeg", ".png"):
            yield img_path


def encode_image_to_data_url(path: Path) -> str:
    """æŠŠæœ¬åœ°å›¾ç‰‡è½¬æˆ data:image/...;base64,xxx å½¢å¼ï¼Œä¾¿äºç›´æ¥å¡åˆ° image_url é‡Œ"""
    suffix = path.suffix.lower()
    if suffix in (".jpg", ".jpeg"):
        mime = "image/jpeg"
    elif suffix == ".png":
        mime = "image/png"
    else:
        mime = "application/octet-stream"
    with path.open("rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    return f"data:{mime};base64,{b64}"


def extract_json(text: str) -> dict:
    """
    å°è¯•ä»æ¨¡å‹è¾“å‡ºä¸­æå– JSONï¼š
    - æˆªå–ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } ä¹‹é—´
    - åšä¸€äº›ç®€å•æ›¿æ¢ï¼ˆä¸­æ–‡æ ‡ç‚¹ã€å°¾é€—å·ã€å•å¼•å·ï¼‰
    """
    stripped = text.strip()

    start = stripped.find("{")
    end = stripped.rfind("}")
    if start == -1 or end == -1 or end <= start:
        raise ValueError("No JSON object found in model output.")
    json_str = stripped[start : end + 1]

    # æ›¿æ¢å¸¸è§ä¸­æ–‡æ ‡ç‚¹ï¼Œé˜²æ­¢ç®€å•é”™è¯¯
    json_str = json_str.replace("ï¼š", ":").replace("ï¼Œ", ",")

    # å»æ‰ } æˆ– ] å‰å¤šä½™çš„é€—å·ï¼š...,}
    json_str = re.sub(r",\s*([}\]])", r"\1", json_str)

    # å°†å•å¼•å·åŒ…è£¹çš„ key/value è½¬æˆåŒå¼•å·ï¼ˆæ¨¡å‹å¶å°”ä¼šç”¨ï¼‰
    json_str = re.sub(r"\'", '"', json_str)

    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        # å†åšä¸€æ¬¡éå¸¸æœ‰é™çš„ä¿®æ­£ï¼šåˆ é™¤ä¸å¯è§å­—ç¬¦åé‡è¯•
        cleaned = "".join(ch for ch in json_str if ch.isprintable())
        return json.loads(cleaned)


def now_iso() -> str:
    return datetime.utcnow().isoformat() + "Z"


# ================== ä¸»é€»è¾‘ï¼šä»…è¡Œç¨‹å• ==================
def main():
    api_key = os.getenv(API_KEY_ENV)
    if not api_key:
        raise RuntimeError(f"è¯·å…ˆåœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® {API_KEY_ENV}")

    client = OpenAI(
        api_key=api_key,
        base_url=BASE_URL,
    )

    # æ”¶é›†æ‰€æœ‰è¦æµ‹çš„å›¾ç‰‡ï¼ˆå…¨éƒ¨è§†ä¸ºè¡Œç¨‹å•ï¼‰
    images = list(iter_images(ROOT_DIR))
    print(f"[INFO] Found {len(images)} images under {ROOT_DIR}")

    task_start_time_iso = now_iso()
    task_start_ts = time.time()

    all_results = {
        "task_start": task_start_time_iso,
        "root_dir": ROOT_DIR,
        "models": [],
    }

    for model_name in MODELS:
        print(f"[MODEL] Running: {model_name}")
        model_start_time_iso = now_iso()
        model_start_ts = time.time()

        model_results = {
            "model": model_name,
            "start_time": model_start_time_iso,
            "cases": [],
        }

        for img_path in images:
            # ========= æ¯å¼ å›¾ç‰‡å¼€å§‹è®¡æ—¶ =========
            img_start_ts = time.time()

            data_url = encode_image_to_data_url(img_path)

            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": TRIP_QUERY,
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": data_url,
                            },
                        },
                    ],
                }
            ]

            completion = client.chat.completions.create(
                model=model_name,
                messages=messages,
                max_tokens=800,
            )

            content = completion.choices[0].message.content

            # æœ‰çš„å…¼å®¹æ¨¡å¼ä¼šè¿”å› listï¼Œæœ‰çš„ç›´æ¥æ˜¯å­—ç¬¦ä¸²ï¼Œè¿™é‡Œåšä¸ªå…¼å®¹
            if isinstance(content, list):
                text_parts = []
                for part in content:
                    if isinstance(part, dict) and part.get("type") == "text":
                        text_parts.append(part.get("text", ""))
                output_text = "".join(text_parts)
            else:
                output_text = content

            # è§£æ JSONï¼ˆå¯èƒ½å¤±è´¥ï¼Œæ‰€ä»¥ç”¨ try/exceptï¼Œæ–¹ä¾¿åé¢æ’æŸ¥ï¼‰
            try:
                parsed = extract_json(output_text)
                parse_error = None
            except Exception as e:
                parsed = None
                parse_error = str(e)

            # ========= æ¯å¼ å›¾ç‰‡ç»“æŸè®¡æ—¶ =========
            img_elapsed = time.time() - img_start_ts

            # åœ¨ç»ˆç«¯æ‰“å°æ¯å¼ å›¾ç‰‡çš„è€—æ—¶
            print(f"[{model_name}] {img_path.name} parsed in {img_elapsed:.2f}s")

            case_result = {
                "_file": str(img_path),
                "output_raw": output_text,   # åŸå§‹æ–‡æœ¬è¾“å‡ºï¼Œæ–¹ä¾¿ debug
                "output": parsed,            # è§£æåçš„ JSONï¼ˆå¦‚å¤±è´¥åˆ™ä¸º Noneï¼‰
                "parse_error": parse_error,  # è§£æé”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æˆåŠŸåˆ™ä¸º Noneï¼‰
                "elapsed_seconds": img_elapsed,  # âœ… æ¯å¼ å›¾ç‰‡çš„è€—æ—¶
            }
            model_results["cases"].append(case_result)

        model_end_time_iso = now_iso()
        model_elapsed = time.time() - model_start_ts
        model_results["end_time"] = model_end_time_iso
        model_results["elapsed_seconds"] = model_elapsed

        all_results["models"].append(model_results)

    task_end_time_iso = now_iso()
    task_elapsed = time.time() - task_start_ts
    all_results["task_end"] = task_end_time_iso
    all_results["task_elapsed_seconds"] = task_elapsed

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)

    print(f"[OK] Wrote results to {OUTPUT_PATH}")


if __name__ == "__main__":
    main()