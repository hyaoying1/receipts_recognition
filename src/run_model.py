import os
import base64
import json
import asyncio
from pathlib import Path
from openai import AsyncOpenAI



BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
API_KEY_ENV = "OPENAI_API_KEY"
MODEL_NAME = "qwen3-vl-8b-instruct"

INPUT_DIR = Path("data/processed")
PROMPT_FILE = "prompt.txt"
CONCURRENCY = 30                



def load_prompt() -> str:
    path = Path(PROMPT_FILE)
    if not path.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ° {PROMPT_FILE}")
    return path.read_text(encoding="utf-8")


def make_data_url(path: Path) -> str:
    """æŠŠå›¾ç‰‡è½¬æˆ Base64 Data URLï¼ˆjpg/pngï¼‰"""
    suffix = path.suffix.lower()
    if suffix in (".jpg", ".jpeg"):
        mime = "image/jpeg"
    elif suffix == ".png":
        mime = "image/png"
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {suffix}")

    data = path.read_bytes()
    b64 = base64.b64encode(data).decode("utf-8")
    return f"data:{mime};base64,{b64}"


def get_image_files(root_dir: Path):
    """éå†å›¾ç‰‡ç›®å½•"""
    exts = [".jpg", ".jpeg", ".png"]
    return [p for p in sorted(root_dir.iterdir()) if p.suffix.lower() in exts]


async def run_inference(client: AsyncOpenAI, image_path: Path, prompt: str, semaphore: asyncio.Semaphore):

    data_url = make_data_url(image_path)

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": data_url}},
            ],
        }
    ]

    async with semaphore:  # é™åˆ¶å¹¶å‘æ•°é‡
        try:
            resp = await client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                max_tokens=200,     # å»ºè®®é™ä½ï¼Œæé«˜é€Ÿåº¦
            )
        except Exception as e:
            return {
                "file": str(image_path),
                "error": str(e)
            }

    # æå–æ–‡æœ¬
    content = resp.choices[0].message.content
    if isinstance(content, list):
        text = "".join([c.get("text", "") for c in content if isinstance(c, dict)])
    else:
        text = content

    return {
        "file": str(image_path),
        "output": text
    }



async def main_async():

    api_key = os.getenv(API_KEY_ENV)
    if not api_key:
        raise RuntimeError("æœªæ£€æµ‹åˆ° OPENAI_API_KEY")

    prompt = load_prompt()
    image_files = get_image_files(INPUT_DIR)

    if not image_files:
        raise RuntimeError(f"åœ¨ {INPUT_DIR} ä¸‹æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")

    print(f"å‘ç° {len(image_files)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹ asyncio å¹¶å‘æ¨ç†...")

    client = AsyncOpenAI(api_key=api_key, base_url=BASE_URL)

    semaphore = asyncio.Semaphore(CONCURRENCY)

    tasks = [
        asyncio.create_task(run_inference(client, img, prompt, semaphore))
        for img in image_files
    ]

    results = await asyncio.gather(*tasks)

    # ä¿å­˜ JSON
    OUTPUT_PATH = Path("outputs/qwen3vl8b_async_results.json")
    OUTPUT_PATH.parent.mkdir(exist_ok=True)
    OUTPUT_PATH.write_text(json.dumps(results, ensure_ascii=False, indent=2), encoding="utf-8")

    print(f"\nğŸ‰ å¼‚æ­¥æ¨ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_PATH}")



if __name__ == "__main__":
    asyncio.run(main_async())
