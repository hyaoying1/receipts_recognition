# ============================================================
# ç¥¨æ®åˆ†ç±»å™¨ - æé€Ÿç²¾ç®€ç‰ˆ
# RapidOCRï¼ˆæœ€å¿«ï¼‰ + Qwen LLM åˆ†ç±»
# ç»Ÿè®¡æ¯å¼ å›¾ç‰‡ OCR ç”¨æ—¶ + LLM ç”¨æ—¶
# ============================================================

from pathlib import Path
from rapidocr_onnxruntime import RapidOCR
from openai import OpenAI
import time

# ==== é…ç½® ====
API_KEY = "sk-88551cce573d49fe81aa466d78c21741"
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
MODEL_NAME = "qwen2.5-7b-instruct"

INPUT_DIR = Path("data/processed")

# åˆå§‹åŒ– OCRï¼ˆæœ€å¿«ï¼‰
ocr = RapidOCR()

# åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
client = OpenAI(api_key=API_KEY, base_url=BASE_URL)


# ============================================================
# OCR
# ============================================================
def run_ocr(path):
    start = time.time()
    result, _ = ocr(path)
    elapsed = time.time() - start

    if result:
        text = "\n".join([line[1] for line in result])
    else:
        text = ""

    return text, elapsed


# ============================================================
# LLM åˆ†ç±»
# ============================================================
def classify_llm(text: str):
    if len(text.strip()) < 5:
        return "other", 0

    prompt = f"""
ä½ æ˜¯ç¥¨æ®åˆ†ç±»åŠ©æ‰‹ï¼Œè¯·æ ¹æ® OCR å†…å®¹åˆ¤æ–­ç¥¨æ®ç±»å‹ï¼Œåªè¾“å‡ºä»¥ä¸‹ä¹‹ä¸€ï¼š

- è¡Œç¨‹å•
- é…’åº—æ°´å•
- æ”¯ä»˜è®°å½•
- å…¶ä»–

OCR æ–‡æœ¬ï¼š
{text}
"""

    start = time.time()

    try:
        resp = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=20
        )
        elapsed = time.time() - start
        answer = resp.choices[0].message.content.strip()
    except Exception:
        return "other", 0

    if "è¡Œç¨‹" in answer:
        return "itinerary", elapsed
    if "é…’åº—" in answer or "æ°´å•" in answer:
        return "hotel_folio", elapsed
    if "æ”¯ä»˜" in answer:
        return "payment", elapsed

    return "other", elapsed


# ============================================================
# ä¸»å‡½æ•°ï¼šå¯¹å•å¼ å›¾ç‰‡è¿›è¡Œå¤„ç†
# ============================================================
def classify_image(image_path):
    print(f"\nğŸ“„ æ–‡ä»¶: {Path(image_path).name}")

    # OCR
    text, ocr_time = run_ocr(image_path)

    # LLM åˆ†ç±»
    category, llm_time = classify_llm(text)

    print(f"  OCRæ—¶é—´: {ocr_time:.4f}s   LLMæ—¶é—´: {llm_time:.4f}s   => åˆ†ç±»ç»“æœ: {category}")

    return category


# ============================================================
# æ‰¹é‡å¤„ç†
# ============================================================
def main():
    if not INPUT_DIR.exists():
        print(f"ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
        return

    images = []
    for ext in ["*.jpg", "*.jpeg", "*.png", "*.bmp"]:
        images.extend(INPUT_DIR.glob(ext))

    if not images:
        print("æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")

    stats = {"itinerary": 0, "hotel_folio": 0, "payment": 0, "other": 0}

    for img in images:
        category = classify_image(str(img))
        stats[category] += 1

    print("\nğŸ“Š ç»Ÿè®¡ç»“æœ")
    for k, v in stats.items():
        print(f"  {k}: {v} å¼ ")


if __name__ == "__main__":
    main()
